{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my geoprocessing to make [transit-score heatmaps](https://johnfwhitesell.github.io/transit/) I had a step where I was simply concatanating two columns of a pandas dataframe to make tuple I would use in my API requests.  Although this is a simple task, repeating it 120,000 times did produce a noticable slowdown.  Previously I would have just shrugged and ignored it unless the delay got too big but now I am aware of the nifty timeit function from python.  In a jupyter notebook all you have to do is define your various functions and call them with %timeit at the start of the line to get a speed estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speedtesting, fun!\n",
    "\n",
    "def iat_assign():\n",
    "    df['XY'] = None\n",
    "    l = df.shape[0]\n",
    "    for i in range(l):\n",
    "        df.iat[i,8] = (df.iat[i,1],df.iat[i,0])\n",
    "        \n",
    "def at_assign():\n",
    "    df['XY'] = None\n",
    "    for i in df.index:\n",
    "        df.at[i,'XY'] = (df.at[i,'lon'], df.at[i,'lat'])\n",
    "\n",
    "def itertuples_at_assign():\n",
    "    df['XY'] = None\n",
    "    for row in df[['lon','lat']].itertuples():\n",
    "        XY = (row[2],row[1])\n",
    "        df.at[row[0], 'XY'] = XY\n",
    "        \n",
    "def itertuples_at_assign_2():\n",
    "    df['XY'] = None\n",
    "    for row in df[['lon','lat']].itertuples():\n",
    "        df.at[row[0], 'XY'] = (row[2],row[1])\n",
    "        \n",
    "def itertuples_iat_assign():\n",
    "    df['XY'] = None\n",
    "    for row in df[['lon','lat']].reset_index().itertuples():\n",
    "        XY = (row[2],row[1])\n",
    "        df.iat[row[0], 8] = XY\n",
    "        \n",
    "%timeit iat_assign()\n",
    "%timeit at_assign()\n",
    "%timeit itertuples_at_assign()\n",
    "%timeit itertuples_at_assign_2()\n",
    "%timeit itertuples_iat_assign()\n",
    "\n",
    "#  Results\n",
    "# iat_assign:\n",
    "# 546 ms ± 8.64 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# at_assign:\n",
    "# 566 ms ± 37.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# itertuples_at_assign:\n",
    "# 228 ms ± 4.22 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# itertuples_at_assign_2:\n",
    "# 223 ms ± 4.11 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# itertuples_iat_assign:\n",
    "# 258 ms ± 14 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These differences aren't huge, only a factor of 2.  Still, there is a really useful lesson here.  It speeds things up to load then process that row rather then looking up over the entire dataframe.  The same thing can be seen in a pairing algorithm used later in the program.  This found which list to assign an object to, then added it to that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def hex_pairing(self):\n",
    "#         # This uses the fact that every point already has calculated the \"id\" of the hex in which it falls, using it's coordinates.\n",
    "#         points = self.points\n",
    "#         hexes = self.hexes        \n",
    "#         points['point_id'] = points.index\n",
    "#         t = tqdm(points.itertuples(), total=points.shape[0])\n",
    "#         print(\"Generating list of values within each hex\")\n",
    "        \n",
    "#         for row in t:\n",
    "#             id = row[2] # this is the id of the hex it matches\n",
    "            \n",
    "#             hex_row = hexes.loc[id]\n",
    "#             hex_row['total_score'].apply(lambda l: l.append(row.total_score))\n",
    "#             hex_row['bike_score'].apply(lambda l: l.append(row.bike_score))\n",
    "#             hex_row['car_score'].apply(lambda l: l.append(row.car_score))\n",
    "#             hex_row['mass_score'].apply(lambda l: l.append(row.mass_score))\n",
    "#             hex_row['ride_score'].apply(lambda l: l.append(row.ride_score))\n",
    "#             hex_row['points_list'].apply(lambda l: l.append(row.point_id))\n",
    "\n",
    "# def hex_pairing_alternative(self):\n",
    "#         # This uses the fact that every point already has calculated the \"id\" of the hex in which it falls, using it's coordinates.\n",
    "#         points = self.points\n",
    "#         hexes = self.hexes        \n",
    "#         points['point_id'] = points.index\n",
    "#         t = tqdm_notebook(points.itertuples(), total=points.shape[0])\n",
    "#         print(\"Generating list of values within each hex\")\n",
    "        \n",
    "#         for row in t:\n",
    "#             id = row[2] # this is the id of the hex it matches           \n",
    "\n",
    "#             hexes.loc[id, 'total_score'].append(row.total_score)\n",
    "#             hexes.loc[id, 'bike_score'].append(row.bike_score)\n",
    "#             hexes.loc[id, 'car_score'].append(row.car_score)\n",
    "#             hexes.loc[id, 'mass_score'].append(row.mass_score)\n",
    "#             hexes.loc[id, 'ride_score'].append(row.ride_score)\n",
    "#             hexes.loc[id, 'points_list'].append(row.point_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the calculations are much longer so I use tqdm instead of %timeit.  Changing your iterator to a tqdm iterator let's you have a progress bar track the progress.  Here I found that loading the row once and editing the row took 2 minutes for 18,000 iterations while loading the row, finding the position and looking up that value took 9 minutes.  That is a more significant difference then what I found before and very important when it comes to making this process scalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test = Washington_grid.hexes\n",
    "# w = grid_rings\n",
    "\n",
    "# %timeit test['integer_form'] = test['grid'].apply(lambda x: x[0]+w+1) + test['grid'].apply(lambda x: x[1]+w+3)*2*w\n",
    "## 8.32 ms ± 193 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "\n",
    "# %timeit test['integer_form']== 2550\n",
    "## 133 µs ± 1.92 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "\n",
    "# %timeit test['grid']==(25,25,25)\n",
    "## 1.24 ms ± 146 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
